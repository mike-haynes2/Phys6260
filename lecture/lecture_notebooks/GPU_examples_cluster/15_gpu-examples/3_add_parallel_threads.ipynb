{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42350f13-04ca-4c3a-a0eb-9b2b0b7cb3fe",
   "metadata": {},
   "source": [
    "# Add with a single thread on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b64c9-6994-4293-a38c-4a138bd29ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e5a1a3-d48e-493c-8558-5288da208869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CUDA function\n",
    "mod = SourceModule(\n",
    "    \"\"\"\n",
    "__global__ void add(int *a, int *b, int *c, int *N)  {\n",
    "  int id = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "\n",
    "  if( id < *N ) {\n",
    "    c[id] = a[id] + b[id];\n",
    "  }\n",
    "}\"\"\"\n",
    ")\n",
    "\n",
    "func = mod.get_function(\"add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f1d12-130d-4f9f-b779-196ac7599929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector size\n",
    "N = numpy.array(1000000)\n",
    "N = N.astype(numpy.int32)\n",
    "\n",
    "# Host vectors\n",
    "a = numpy.arange(0, N)\n",
    "b = 1 - a\n",
    "c = numpy.zeros(N)\n",
    "\n",
    "a = a.astype(numpy.int32)\n",
    "b = b.astype(numpy.int32)\n",
    "c = c.astype(numpy.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bd657-7c66-41d2-91e6-6cddaab38fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate on device\n",
    "a_gpu = cuda.mem_alloc(a.size * a.dtype.itemsize)\n",
    "b_gpu = cuda.mem_alloc(b.size * b.dtype.itemsize)\n",
    "c_gpu = cuda.mem_alloc(c.size * c.dtype.itemsize)\n",
    "N_gpu = cuda.mem_alloc(N.size * N.dtype.itemsize)\n",
    "\n",
    "# Copy from host to device\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "cuda.memcpy_htod(b_gpu, b)\n",
    "cuda.memcpy_htod(N_gpu, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275c257-40cd-47c0-a74c-dfc372602518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of threads per block\n",
    "threadCount = 128\n",
    "\n",
    "# Number of blocks per grid\n",
    "blockCount = int(numpy.ceil(float(N) / threadCount))\n",
    "\n",
    "func(a_gpu, b_gpu, c_gpu, N_gpu, block=(threadCount, 1, 1), grid=(blockCount, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433fd883-da9f-49d8-ab71-67c1a1389201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy result to host\n",
    "cuda.memcpy_dtoh(c, c_gpu)\n",
    "\n",
    "# Display results\n",
    "print(\"Should be %d\" % N)\n",
    "print(\"Results: %d\" % numpy.sum(c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
