{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3b0814-f396-4210-a37f-47768893b1f9",
   "metadata": {},
   "source": [
    "# Lecture 03-24: Convolutional Neural Networks (CNNs)\n",
    "### Operations in a Convolutional Neural Network\n",
    "\n",
    "- In a typical neural network, the information is vectorized and passed in without any information connecting different elements (other than what is incorporated in the data and loss function)\n",
    "\n",
    "#### Convolutional Neural Networks incorporate Topological relationships\n",
    "Consider the image example, where an image is passed in as a vector of pixels. There are certain properties of CNNs in this regard:\n",
    "\n",
    "- _Locality_: nearby pixels are more strongly correlated\n",
    "- _Translational invariance_: meaningful patterns can occur anywhere in the image\n",
    "- _Weight sharing_: use the same network parameters to detect local patterns at many locations in the image\n",
    "- _Heirarchy_: local low-level features are composed into larger, more abstract features\n",
    "\n",
    "#### How connection is encoded\n",
    "\n",
    "A _fully-connected unit_ is a weighted sum of all pixels.\n",
    "\n",
    "A _locally connected unit_ is computed by spatially varying a filter, such as a restriction in proximity to other pixels involved in the unit\n",
    "\n",
    "_Pooling_ is used to reduce resolution, i.e., downscale an image. This is often done by computing the mean or max of a small subset of pixels, rescaling the resolution to the resolution of the small pixel. \n",
    "\n",
    "#### Steps of a CNN\n",
    "\n",
    "1. Fully-connected layer\n",
    "2. Locally-connected layer\n",
    "3. Convolutional layer (using filters to subdivide the image into different \"blocks\")\n",
    "4. Recomposition of image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a06f01-aa4d-4c35-8e3f-a03361eb1f86",
   "metadata": {},
   "source": [
    "### Progression of CNNs\n",
    "\n",
    "#### AlexNet (2012)\n",
    "- Architecture: 8 layers, ReLU, (+ dropout & weight decay)\n",
    "- Trained on 2 GPUs for 6 days (1.2 million images)\n",
    "- Krizhevsky et al., 2012 ImageNet Classification with deep convolutional neural networks\n",
    "- For about 150k inputs, the number of neurons is about 660k\n",
    "- Trained using stochastic gradient descent\n",
    "\n",
    "\"Deeper is better\"\n",
    "\n",
    "Each layer is a linear classifier alone. The more combined layers, the better chance you have of accounting for the complexity of possible predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af699422-dff4-4e01-b67c-b02e5c58b2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
