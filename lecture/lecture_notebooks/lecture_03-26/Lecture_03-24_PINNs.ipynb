{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b73363-2673-4a25-9add-89e45665fa7e",
   "metadata": {},
   "source": [
    "# Lecture 03/24: Physics-Informed Neural Networks (PINNs)\n",
    "### Approach: background, methodology, examples\n",
    "\n",
    "The key concept of a physics-informed neural network is modifying the loss function (i.e., the perscribed error that is minimized by the algorithm). By writing the physical laws governing the system in a form compatible with your system, the physical laws themselves can be _encoded_ in the neural network through inclusion of a term that should sum to zero in the loss function. For example, the loss $\\mathcal{L}$ is comprised of $\\mathcal{L}_{\\mathrm{error}}$ and $\\mathcal{L}_{\\mathrm{physical}}$, such that\n",
    "$$\\mathcal{L}=\\mathcal{L}_{\\mathrm{error}} + \\mathcal{L}_{\\mathrm{physical}}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\min{\\mathcal{L}} = \\min{\\left[\\mathcal{L}_{\\mathrm{error}} + \\mathcal{L}_{\\mathrm{physical}}\\right]} $$\n",
    "\n",
    "The error from the PDE governing the physical system, $\\mathcal{L}_{\\mathrm{physical}}$, is called the _residual_ of the PDE or law. \n",
    "\n",
    "Since PDEs themselves do not specify the behavior of the system, the initial conditions and boundary conditions must likewise be incorporated in separate terms of the loss function. \n",
    "\n",
    "With each additional term, the landscape of the loss function in higher dimensional space becomes more and more noisy / volatile. This can spark _reduced_ performance in the PINN compared to one that only uses data, without the physical laws. There are, however, methods to circumvent these effects. One such method is **Curriculum Learning**. \n",
    "\n",
    "For example, we would train the advection equation PINN using only a small portion of the dataset: namely, train it for a specific regime of velocities or solutions, and gradually expand its scope after it learns a single zone. The alternative approach is to pose the problem as a sequence to learn sequentially, where the PINN learns to predict the solution in a finite time horizon and iteratively predicts the following time windows. \n",
    "\n",
    "Another such technique is _adaptive sampling_. Similar to Importance Sampling in monte carlo simulations, this method adaptively distributes the sampling of points in the training phase, to focus strongly on the areas with steep gradients / lots of information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea672fc-58f3-4e05-bd7d-666daa436d8f",
   "metadata": {},
   "source": [
    "### Example PDEs:\n",
    "- Advection Equation\n",
    "- Reaction Diffusion Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18796118-dbcf-417e-95dd-1f0282e7ba97",
   "metadata": {},
   "source": [
    "## Supervised learning vs. sequence modelling:\n",
    "#### Supervised learning:\n",
    "- data: ${x_i,y_i}$\n",
    "- model: $y \\approx f_\\theta(x)$\n",
    "- Loss: $\\mathcal{L} = \\sum_i^N l(f_\\theta(x_i),y_i)$\n",
    "- Optimization: $\\theta^* = \\arg\\min_\\theta (\\mathcal{L})$\n",
    "\n",
    "#### Sequence Modelling:\n",
    "- data: ${x_i}$\n",
    "- model: $p(x) \\approx f_\\theta(x)$\n",
    "- Loss: $\\mathcal{L} = \\sum_i^N \\log p(f_\\theta(x_i))$\n",
    "- Optimization: $\\theta^* = \\arg\\max_\\theta (\\mathcal{L})$\n",
    "$\\implies$ the sequence modelling approach does NOT use any known data (i.e., outputs $y_i$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc2d372-bb7f-4022-95e6-19e8acc0495a",
   "metadata": {},
   "source": [
    "# The Transformer\n",
    "#### Created by Google Brain\n",
    "- NN that learns context and thus meaning\n",
    "- Tracks relationships in sequential data, like words in a sentence\n",
    "- Applies an evolving set of operations, called attention\n",
    "- Detects subtle ways that distant data elements can influence and depend on each other\n",
    "- Now known as a self-supervised method or a “foundational” method\n",
    " \n",
    "#### The positional encoder\n",
    "- tracks where the element is in the sequence\n",
    "- Complex functions like\n",
    "$$ \\sin{\\left( \\frac{\\mathrm{pos}}{10,000^{\\frac{2i}{d}} } \\right)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2cb5a-6f32-4263-9e89-73c1574158e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
