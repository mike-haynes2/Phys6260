{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459d9a2e-c8f7-45f7-b873-7390bae5b57d",
   "metadata": {},
   "source": [
    "# PHYS 6260: Homework 5, C. Michael Haynes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc6d81-b6c8-4213-ac04-f7ac043c2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic list of import statements to not have to keep track\n",
    "import numpy as np\n",
    "from scipy import constants\n",
    "import math as m\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "from random import random,randrange\n",
    "\n",
    "# importing specific to animation formalism found in the template notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "plt.rcParams['animation.html'] = 'html5' # this is used to display animations in jupyter notebooks\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "warnings.filterwarnings( \"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e982c0ea-31f6-41d5-be1f-a0548fb3fc78",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "### Monte Carlo Integration\n",
    "We wish to use the Importance Sampling technique to evaluate \n",
    "$$ I = \\int_{a=0}^{b=1} \\frac{x^{-\\frac{1}{2}}}{e^x + 1} \\, \\mathrm{d}x \\qquad .$$\n",
    "This method uses a non-uniform random sample to evaluate the integral without encountering evaluation issues near the point where the function diverges (i.e., the origin). \n",
    "\n",
    "#### (a) Choice of Probability Distribution $p(x)$\n",
    "\n",
    "As discussed in lecture, this is acheived by selecting a _weighting function_ $w(x)$ that factors out the diverging product. Since the function \n",
    "$$ f(x) = \\frac{x^{-\\frac{1}{2}}}{e^x + 1}$$\n",
    "diverges on $[a,b]$ due to the $x^{-\\frac{1}{2}}$ factor, we choose $w(x) \\equiv x^{-\\frac{1}{2}}$ such that \n",
    "$$ \\frac{f(x)}{w(x)} = \\frac{ \\frac{x^{-\\frac{1}{2}}}{e^x + 1}}{x^{-\\frac{1}{2}}} = \\frac{1}{e^x + 1} \\qquad ,$$\n",
    "which is well-behaved.\n",
    "\n",
    "Now, since this choice of the weighting function $w$ eliminates the divergent product, we can determine a probability distribution based on the formalism outlined in the lecture slides (specifically, slide set 09: pg 14):\n",
    "$$ p(x) = \\frac{w(x)}{\\int_a^bw(x)\\mathrm{d}x} = \\frac{x^{-\\frac{1}{2}}}{\\int_0^1 x^{-\\frac{1}{2}}\\mathrm{d}x} \\qquad .$$\n",
    "When the integral in the denominator is evaluated, this simply becomes\n",
    "$$ p(x) = \\frac{1}{2x^{\\frac{1}{2}}} \\qquad ,$$ \n",
    "as found in the prompt. \n",
    "\n",
    "We map the image of $p(x)$ to the interval $[0,1]$ via\n",
    "$$ M(p(x)) \\mapsto \\frac{p(x)}{1+p(x)} $$\n",
    "so that\n",
    "$$\\DeclareMathOperator{\\Ima}{Im} \\Ima{M} \\sim \\frac{\\Ima{p}}{\\Ima{p}+1} \\mapsto [0,1] \\qquad .$$\n",
    "Thus, by selecting numbers $x_i$ from $p(x)$ and passing them through the map $M$, we can obtain a weighted set of $x$ values of arbitrary size on the interval $[0,1]$. \n",
    "\n",
    "Another choice is the function\n",
    "$$ M_2(x) = \\frac{2\\arctan{x}}{\\pi} $$ \n",
    "with accompanying inverse mapping\n",
    "$$ M_2^{-1} = \\tan{\\left ( \\frac{\\pi x}{2} \\right ) }  \\qquad .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716fec10-b653-4cfb-b1a0-62f83cabe4b6",
   "metadata": {},
   "source": [
    "#### (b) Evaluate the Integral\n",
    "To do so, we will implement a numerical routine to approximate the integral of $f(x)$ over $[a,b]$ with the expression obtained in lecture using the Importance Sampling formalism:\n",
    "$$ I \\approx \\frac{1}{N} \\sum_{i=1}^N \\frac{f(x_i)}{w(x_i)} \\int_a^b w(x) \\,\\mathrm{d}x \\qquad , $$\n",
    "for a MC process with $N$ samples. Substituting our expressions for $f(x),\\,w(x),$ we have:\n",
    "$$ I \\approx \\frac{1}{N} \\sum_{i=1}^N \\frac{2}{e^{x_i} + 1} \\qquad , $$ \n",
    "where the sample points $x_i$ are obtained from $M(p(x))$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7928f000-63cc-4b43-a9f1-085e625c8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define probability function p(x)\n",
    "def p(x):\n",
    "    return (1./(2.*np.sqrt(x)))\n",
    "\n",
    "# define mappings M, M2 that go between the domains [0,1] and [0, infty)\n",
    "def M(x):\n",
    "    return (x/(x+1.))\n",
    "\n",
    "def Minv(x):\n",
    "    return (x/(1.-x))\n",
    "\n",
    "def M2(x):\n",
    "    return (2. * np.arctan(x) / np.pi)\n",
    "\n",
    "def Minv2(x):\n",
    "    return (np.tan(np.pi * x / 2.))\n",
    "\n",
    "# define function to calculate the integral of the Fermi distribution\n",
    "# inputs: N samples, mapping M and inverse mapping Minv\n",
    "# since Minv maps [0,1] to [0,infty), we use this to initialize our xi values\n",
    "\n",
    "def IS_Fermi(N,M,Minv):\n",
    "    xi_ar = []\n",
    "    for j in range(N):\n",
    "        xi_ar.append(np.random.random())\n",
    "    xi_ar = np.array(xi_ar)\n",
    "    xi_arr = Minv(xi_ar)\n",
    "    pxi_arr = p(xi_arr)\n",
    "    Mpxi_arr = M(pxi_arr)\n",
    "    eval_arr = 2. / (1.+np.exp(Mpxi_arr))\n",
    "    Ninv = 1./N\n",
    "    return (Ninv * eval_arr.sum())\n",
    "\n",
    "\n",
    "def pk(k,N,M,Minv):\n",
    "    vals = []\n",
    "    for i in range(k):\n",
    "        vals.append(IS_Fermi(N,M,Minv))\n",
    "    stats = np.array(vals)\n",
    "    for i in range(k):\n",
    "        print('sample '+str(i+1)+': '+str(IS_Fermi(N,M,Minv)))\n",
    "    print('mean: '+str(np.mean(stats)))\n",
    "\n",
    "print('--------------\\nFive N=1e6 samples using polynomial mapping M:\\n--------------')\n",
    "pk(5,int(1e6),M,Minv)\n",
    "print('--------------\\nFive N=1e6 samples using trigonometric mapping M2:\\n--------------')\n",
    "pk(5,int(1e6),M2,Minv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabd0298-a284-4297-97ff-1727b4236db5",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "### Randomizing a vector bearing\n",
    "As shown in the homework prompt, the probability of a randomly selected point on a sphere falling within any particular element is given by:\n",
    "\n",
    "$$p(\\theta,\\phi)\\,\\mathrm{d}\\theta\\,\\mathrm{d}\\phi = \\frac{\\sin{\\theta\\,\\mathrm{d}\\theta\\,\\mathrm{d}\\phi}}{4\\pi} \\qquad ,$$ \n",
    "\n",
    "which can be decomposed into a product of single variable functions:\n",
    "\n",
    "$$p(\\theta,\\phi)\\,\\mathrm{d}\\theta\\,\\mathrm{d}\\phi = \\frac{\\sin{\\theta \\,\\mathrm{d}\\theta}}{2} \\cdot \\frac{\\mathrm{d} \\phi}{2\\pi} = p(\\theta)\\,\\mathrm{d}\\theta \\cdot p(\\phi)\\,\\mathrm{d}\\phi \\qquad .$$\n",
    "\n",
    "\n",
    "#### (a) Distributions for $\\theta,\\phi$\n",
    "\n",
    "The variables $\\theta$ and $\\phi$ represent colatitude and longitude, respectively. Longitude covers $360^\\circ$ and latitude only $180^\\circ$, so the ranges of the two variables are given by:\n",
    "$$\\theta\\in[0,\\pi] \\qquad , \\qquad \\phi\\in[0,2\\pi] \\qquad .$$\n",
    "\n",
    "The normalization can thus be verified directly via integration. For $\\theta$:\n",
    "$$ \\int_0^\\pi \\frac{sin{\\theta}}{2} \\,\\mathrm{d}\\theta = \\frac{1}{2} \\left ( -\\cos{\\theta} \\big\\vert_0^\\pi \\right ) = - \\frac{1}{2} (-1 -1) = 1 $$\n",
    "For $\\phi$, it is trivial:\n",
    "$$\\int_0^{2\\pi} \\frac{1}{2\\pi} \\,\\mathrm{d}\\phi = \\frac{2\\pi}{2\\pi} = 1 \\qquad . $$\n",
    "\n",
    "\n",
    "\n",
    "#### (b) Randomly Sampling the distributions $p(\\theta),\\,p(\\phi)$\n",
    "\n",
    "As stated, the $\\phi$ one is trivial since this is a uniform distribution over the interval $[0,2\\pi]$. Thus, a randomly selected $\\phi$ would merely be a random number on the unit interval multiplied by $2\\pi$. \n",
    "\n",
    "$$ P(\\phi) = \\frac{\\phi}{2\\pi} $$\n",
    "\n",
    "For $\\theta$, however, the case is less clear. Since this is _not_ a uniform distribution, we need to obtain the inverse CDF to transform a uniformly generated random number into a value from $p(\\theta)$. This can be obtained via integration:\n",
    "\n",
    "$$ P(\\theta) = \\int_0^\\theta p(\\theta') \\,\\mathrm{d}\\theta' = \\int_0^\\theta  \\frac{\\sin{\\theta'}}{2}  \\,\\mathrm{d}\\theta' $$\n",
    "$$ P(\\theta) = \\frac{1-\\cos{\\theta}}{2} $$\n",
    "\n",
    "Then, by inverting these CDFs we can obtain an expression mapping a random number on the unit interval to these PDFs determined by our spherical geometry. Doing so yields:\n",
    "\n",
    "$$ \\phi = 2 \\pi r $$\n",
    "$$ \\theta = \\arccos{(1-2r)} $$\n",
    "\n",
    "#### (c) Routine for random point generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387acd1-1acc-4957-9718-bb9ce3a8eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for inverse CDF of phi\n",
    "def f_phi(r):\n",
    "    return (2. * np.pi * r)\n",
    "\n",
    "# function for inverse CDF of theta\n",
    "def f_theta(r):\n",
    "    return (m.acos(1. - 2. * r))\n",
    "\n",
    "# function for generating a random point on a sphere\n",
    "def rand_point_sphere(radius):\n",
    "    r_mag = radius\n",
    "    r1, r2 = np.random.random(),np.random.random()\n",
    "    phi = f_phi(r1)\n",
    "    theta = f_theta(r2)\n",
    "    x = r_mag * m.sin(theta) * m.cos(phi)\n",
    "    y = r_mag * m.sin(theta) * m.sin(phi)\n",
    "    z = r_mag * m.cos(theta)\n",
    "    return np.array([x,y,z])\n",
    "\n",
    "x = rand_point_sphere(1.)\n",
    "\n",
    "\n",
    "# brielfy plot for sanity, as shown in starter code\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(x[0], x[1], x[2], c='r', marker='o')\n",
    "# plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be881e85-0a66-4bce-ac0c-a47c02a47d32",
   "metadata": {},
   "source": [
    "#### (d) Routine for random point mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970e7eb-1122-45ab-96dc-988c6157876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to stabalize the 3D plot viewing\n",
    "\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_mid = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_mid = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_mid = np.mean(z_limits)\n",
    "    \n",
    "    plot_radius = (1./2.)*max([x_range, y_range, z_range])\n",
    "    \n",
    "    ax.set_xlim3d([x_mid - plot_radius, x_mid + plot_radius])\n",
    "    ax.set_ylim3d([y_mid - plot_radius, y_mid + plot_radius])\n",
    "    ax.set_zlim3d([z_mid - plot_radius, z_mid + plot_radius])\n",
    "\n",
    "\n",
    "# define arrays to store entries for each coordinate\n",
    "X, Y, Z = [],[],[]\n",
    "# iterate 500 instances\n",
    "for i in range(500):\n",
    "    k_vec = rand_point_sphere(1.)\n",
    "    X.append(k_vec[0])\n",
    "    Y.append(k_vec[1])\n",
    "    Z.append(k_vec[2])\n",
    "\n",
    "# plot, as shown in the starter code\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X, Y, Z, c='r', marker='o')\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$z$')\n",
    "set_axes_equal(ax)\n",
    "plt.title('Random points on a globe of radius 1')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## NOTE: I was unable to activate the ipympl library on my machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae3c80-1be7-4f9a-8dce-0d93f9a08bb9",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "### Application Question\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5937bc-c550-42fc-a23f-8a5731845c4a",
   "metadata": {},
   "source": [
    "Many systems studied in continuum physics exhibit processes that can be modeled with Monte Carlo (MC) methods. One example of such processes is the behavior of a plasma, for instance, as it impinges towards an obstacle like the Earth's (or another planet's) magnetosphere. For objects with or without a strong internal magnetic field, this flow couples strongly to the ionosphere of the object: it generates production of ions, modifies / shapes the current systems, and likewise contributes to its outflow and loss. \n",
    "\n",
    "In some plasma simulation codes, the ion motion occurs on scales large enough to produce asymmetries in this interaction, so many numerical approaches include a _kinetic_ treatment of ions with a fluid (MHD) treatment of electrons: this is known as a hybrid model. Ionospheric production occurs through chemical reactions. These individual particle interactions, such as charge exchange or photo-ionization via solar uv rays, are calculated in many hybrid models using a MC process like the one we used in the Rutherford scattering example from lecture. The probability of the interaction can be computed with the interaction cross section. Thus, many aspects of ionospheric generation, current balance, and loss can be attributed to a net result of many small-scale MC simulations. \n",
    "\n",
    "Moreover, some numerical applications can substantiate the use of a MC approach, too. For example, in many hybrid and/or kinetic plasma models, particles are traced as _macroparticles_: that is, they represent an ensemble of particles near a certain coordinate in phase space. These are traced together and sampled from distribution functions obtained through measurement, when possible. These macroparticles thus represent different (usually large) numbers of real particles. The number of macroparticles to trace, then, is a choice to be made by the simulation. It is possible to specify an \"optimum\" number of macroparticles in each grid node, and then use merging / splitting processes (which approximately conserve COM, energy and momentum) to adjust the number of macroparticles in each cell after the particles are advanced and some may cross over into adjacent grid cells. The coordinates with which to initialize these particles needs to be sampled from a distribution using a MC approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a3708-b40e-434f-b8fd-d921723eb692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
